---
title: "Story 4.3 - Metrics Calculation: Latency Percentiles, Error Rates, Queue Depth"
status: "Ready for Development"
epic: "Epic 4: Observability & Tail Worker Logs Display"
priority: "P0"
story_size: "Large"
estimated_hours: 6
created_at: "2025-11-11"
modified_at: "2025-11-11"
---

## Summary

Implement comprehensive metrics calculation pipeline that computes latency percentiles (p50, p95, p99), error rates, throughput metrics, and queue depth from stored logs and system state. Metrics are continuously updated and stored in KV for fast dashboard access.

## Business Value

Provides quantitative insights into system performance and health. Metrics enable performance monitoring, trend analysis, and identification of degradation. Percentile-based metrics reveal tail latencies that affect user experience.

## Technical Context

**From PRD (FR-4.2: Metrics Collection):**
- System MUST track in KV:
  - Total events ingested
  - Events by status (pending/delivered/failed)
  - Queue depth
  - Dead Letter Queue message count
  - Error rates
  - Processing latency percentiles (p50, p95, p99)
- Metrics MUST update in real-time or near-real-time

**From Architecture (Performance Considerations):**
- Target < 100ms for POST /events at p95
- Target < 200ms for GET /inbox at p95
- Leverage KV for fast metric access (eventual consistency acceptable)

## Acceptance Criteria

1. **Latency Percentile Calculation**
   - Calculates p50 (median), p95, p99 latencies from logs
   - Uses duration_ms from log_entries for calculations
   - Separates metrics by endpoint (/events, /inbox, /inbox/:id/ack, /inbox/:id/retry)
   - Percentiles calculated from last 1000 requests per endpoint
   - Updates every 30 seconds or on new 100 logs
   - Stores results in KV: metrics:latency:p50, metrics:latency:p95, metrics:latency:p99

2. **Error Rate Calculation**
   - Calculates errors per minute (count and percentage)
   - Tracks error rate by endpoint
   - Separates by error type: validation, auth, not_found, conflict, server
   - Compares 4xx vs 5xx rates
   - Rolling 5-minute error rate window
   - Stores in KV: metrics:errors:rate, metrics:errors:by_type

3. **Request Success Calculation**
   - Calculates successful request percentage (2xx responses)
   - Tracks by endpoint
   - Rolling 5-minute success rate window
   - Success rate = (2xx count / total requests) * 100
   - Stores in KV: metrics:success:rate

4. **Queue Depth Tracking**
   - Queries Cloudflare Queue API for current depth
   - Calculates pending event count from D1 (status='pending')
   - Tracks Dead Letter Queue message count
   - Stores snapshots every 5 seconds
   - Enables queue depth trend analysis
   - Stores in KV: metrics:queue:depth, metrics:dlq:count

5. **Throughput Metrics**
   - Calculates events processed per second
   - Tracks by endpoint
   - Rolling 1-minute throughput window
   - Average request rate (requests/second)
   - Peak request rate in current window
   - Stores in KV: metrics:throughput:eps, metrics:throughput:rps

6. **Event Lifecycle Metrics**
   - Tracks events by status: pending, delivered, failed
   - Counts total events ingested (lifetime)
   - Calculates event delivery rate (delivered/ingested)
   - Tracks retry counts and success rate on retries
   - Stores in KV: metrics:events:total, metrics:events:by_status

7. **Database Query Performance**
   - Measures D1 query execution time (if available)
   - Tracks slow queries (> 100ms)
   - Calculates database efficiency metrics
   - Stores in KV: metrics:db:avg_query_time, metrics:db:slow_queries

8. **Worker Execution Time**
   - Captures CPU execution time from Tail Worker data
   - Calculates CPU percentiles (p50, p95, p99)
   - Identifies CPU-intensive operations
   - Tracks by worker (api-worker, queue-consumer, etc.)
   - Stores in KV: metrics:cpu:p50, metrics:cpu:p95, metrics:cpu:p99

9. **Payload Size Metrics**
   - Calculates average request payload size
   - Calculates average response payload size
   - Tracks maximum payload size seen
   - Identifies oversized payloads
   - Stores in KV: metrics:payload:avg_request, metrics:payload:avg_response

10. **Real-Time Aggregation**
    - Updates metrics in near real-time (< 5 second lag)
    - Efficient incremental updates (not full recalculation)
    - Uses KV atomic operations for counter increments
    - Batches metric updates to minimize KV writes
    - Handles high-frequency metric updates

11. **Historical Metrics Storage**
    - Stores historical snapshots in D1 (metrics_history table)
    - Snapshots every 1 minute
    - Enables trend analysis and alerting
    - Maintains 30-day retention
    - Supports dashboards showing graphs over time

12. **Percentile Algorithm Efficiency**
    - Uses efficient percentile calculation (not sorting full list)
    - Maintains sorted window of recent latencies
    - Updates incrementally as new logs arrive
    - O(n log n) complexity for new batch, O(log n) for query
    - Processes latency calculations < 1 second per endpoint

13. **Metrics Consistency**
    - Ensures metrics are eventually consistent (KV eventual consistency)
    - Metrics queryable within 5 seconds of event
    - Handles clock skew gracefully
    - Atomic updates for related metrics
    - No partial/invalid metric states visible

14. **Metric Validation**
    - Validates metric calculations (sanity checks)
    - Detects and handles calculation errors gracefully
    - Filters outliers (e.g., latency spikes > 10x normal)
    - Ensures percentiles are in valid order (p50 < p95 < p99)
    - Stores confidence level with metrics

15. **API Endpoint for Metrics**
    - Implements GET /metrics endpoint (not in MVP, documented for later)
    - Returns all current metrics in JSON format
    - Supports filtering by time range
    - Supports filtering by endpoint
    - Returns metrics with timestamp

## Dependencies

- **Story 4.1:** Tail Worker capturing execution data
- **Story 4.2:** Log processing storing parsed logs in log_entries
- **Epic 3 Complete:** Queue and D1 already functional

## Technical Specifications

### D1 Metrics History Table

```sql
CREATE TABLE metrics_history (
  metric_id TEXT PRIMARY KEY,
  metric_type TEXT NOT NULL,        -- latency, error_rate, throughput, etc
  endpoint TEXT,                    -- /events, /inbox, etc (if applicable)
  value REAL NOT NULL,              -- numeric value
  unit TEXT,                        -- ms, %, rps, etc
  timestamp TEXT NOT NULL,          -- when calculated
  data_points INTEGER,              -- how many logs used in calculation
  confidence REAL,                  -- 0-1, confidence in metric
  created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_metrics_timestamp ON metrics_history(timestamp DESC);
CREATE INDEX idx_metrics_type ON metrics_history(metric_type);
CREATE INDEX idx_metrics_endpoint ON metrics_history(endpoint);
CREATE INDEX idx_metrics_type_endpoint ON metrics_history(metric_type, endpoint);
```

### KV Storage Structure

```typescript
// Latency metrics (milliseconds)
metrics:latency:p50 = { value: 45, timestamp: "2025-11-11T12:34:56Z", endpoint: "/events" }
metrics:latency:p95 = { value: 120, timestamp: "2025-11-11T12:34:56Z", endpoint: "/events" }
metrics:latency:p99 = { value: 250, timestamp: "2025-11-11T12:34:56Z", endpoint: "/events" }

// Error metrics
metrics:errors:rate = { value: 2.5, unit: "percent", timestamp: "2025-11-11T12:34:56Z" }
metrics:errors:by_type = {
  validation: 10,
  auth: 5,
  server: 3,
  timestamp: "2025-11-11T12:34:56Z"
}

// Success rate
metrics:success:rate = { value: 97.5, unit: "percent", timestamp: "2025-11-11T12:34:56Z" }

// Queue metrics
metrics:queue:depth = { value: 42, timestamp: "2025-11-11T12:34:56Z" }
metrics:dlq:count = { value: 3, timestamp: "2025-11-11T12:34:56Z" }

// Throughput
metrics:throughput:eps = { value: 15.5, unit: "events/sec", timestamp: "2025-11-11T12:34:56Z" }
metrics:throughput:rps = { value: 18.2, unit: "requests/sec", timestamp: "2025-11-11T12:34:56Z" }

// Event counts
metrics:events:total = 5432
metrics:events:pending = 45
metrics:events:delivered = 5300
metrics:events:failed = 87

// CPU metrics
metrics:cpu:p50 = { value: 12, unit: "ms", timestamp: "2025-11-11T12:34:56Z" }
metrics:cpu:p95 = { value: 35, unit: "ms", timestamp: "2025-11-11T12:34:56Z" }
metrics:cpu:p99 = { value: 48, unit: "ms", timestamp: "2025-11-11T12:34:56Z" }
```

### Metrics Calculator Implementation

```typescript
// src/lib/metrics-calculator.ts
import { D1Database } from '@cloudflare/workers-types';

export interface LatencyMetrics {
  p50: number;
  p95: number;
  p99: number;
  max: number;
  avg: number;
  count: number;
  endpoint: string;
}

export interface ErrorMetrics {
  total_errors: number;
  error_rate: number; // percentage
  by_type: Record<string, number>;
  by_status: { '4xx': number; '5xx': number };
}

export class MetricsCalculator {
  constructor(
    private db: D1Database,
    private kv: KVNamespace,
    private logger: any
  ) {}

  async calculateLatencyPercentiles(): Promise<void> {
    try {
      const endpoints = ['/events', '/inbox', '/inbox/:id/ack', '/inbox/:id/retry'];

      for (const endpoint of endpoints) {
        // Get last 1000 requests for this endpoint
        const result = await this.db.prepare(`
          SELECT duration_ms FROM log_entries
          WHERE endpoint = ? AND status_code < 500
          ORDER BY timestamp DESC
          LIMIT 1000
        `).bind(endpoint).all();

        if (!result.results || result.results.length === 0) continue;

        const latencies = (result.results as any[])
          .map(r => r.duration_ms)
          .filter(l => l > 0)
          .sort((a, b) => a - b);

        const metrics = {
          endpoint,
          p50: this.percentile(latencies, 50),
          p95: this.percentile(latencies, 95),
          p99: this.percentile(latencies, 99),
          max: Math.max(...latencies),
          avg: latencies.reduce((a, b) => a + b, 0) / latencies.length,
          count: latencies.length,
          timestamp: new Date().toISOString(),
        };

        // Store in KV
        await this.kv.put(
          `metrics:latency:${endpoint}`,
          JSON.stringify(metrics),
          { expirationTtl: 3600 } // 1 hour TTL
        );

        // Store in history
        await this.storeMetricHistory('latency_p50', endpoint, metrics.p50, 'ms');
        await this.storeMetricHistory('latency_p95', endpoint, metrics.p95, 'ms');
        await this.storeMetricHistory('latency_p99', endpoint, metrics.p99, 'ms');
      }

      this.logger.info('Latency percentiles calculated');
    } catch (error) {
      this.logger.error('Failed to calculate latency metrics', { error: String(error) });
    }
  }

  async calculateErrorRate(): Promise<void> {
    try {
      // Get errors from last 5 minutes
      const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000).toISOString();

      const result = await this.db.prepare(`
        SELECT
          COUNT(*) as total_requests,
          SUM(CASE WHEN status_code >= 400 THEN 1 ELSE 0 END) as total_errors,
          SUM(CASE WHEN status_code >= 400 AND status_code < 500 THEN 1 ELSE 0 END) as client_errors,
          SUM(CASE WHEN status_code >= 500 THEN 1 ELSE 0 END) as server_errors,
          error_category,
          COUNT(*) as error_count
        FROM log_entries
        WHERE timestamp > ?
        GROUP BY error_category
      `).bind(fiveMinutesAgo).all();

      if (!result.results) return;

      const rows = result.results as any[];
      let totalErrors = 0;
      let totalRequests = 0;
      const errorsByType: Record<string, number> = {};

      for (const row of rows) {
        totalRequests += row.total_requests || 0;
        totalErrors += row.total_errors || 0;
        if (row.error_category) {
          errorsByType[row.error_category] = row.error_count;
        }
      }

      const errorRate = totalRequests > 0 ? (totalErrors / totalRequests) * 100 : 0;

      const metrics = {
        total_errors: totalErrors,
        error_rate: Math.round(errorRate * 10) / 10, // 1 decimal place
        total_requests: totalRequests,
        by_type: errorsByType,
        timestamp: new Date().toISOString(),
      };

      await this.kv.put(
        'metrics:errors:rate',
        JSON.stringify(metrics),
        { expirationTtl: 600 } // 10 minute TTL
      );

      this.logger.info('Error rate calculated', { rate: metrics.error_rate });
    } catch (error) {
      this.logger.error('Failed to calculate error metrics', { error: String(error) });
    }
  }

  async calculateThroughput(): Promise<void> {
    try {
      // Get throughput from last 1 minute
      const oneMinuteAgo = new Date(Date.now() - 60 * 1000).toISOString();

      const result = await this.db.prepare(`
        SELECT
          COUNT(*) as request_count,
          endpoint,
          CASE WHEN status_code < 400 THEN 'success' ELSE 'error' END as status
        FROM log_entries
        WHERE timestamp > ?
        GROUP BY endpoint, status
      `).bind(oneMinuteAgo).all();

      const rows = result.results as any[];
      let totalRequests = 0;

      for (const row of rows) {
        totalRequests += row.request_count;
      }

      const rps = totalRequests / 60; // requests per second
      const eps = rps; // events per second (same for API requests)

      const metrics = {
        rps: Math.round(rps * 100) / 100,
        eps: Math.round(eps * 100) / 100,
        total_requests: totalRequests,
        timestamp: new Date().toISOString(),
      };

      await this.kv.put(
        'metrics:throughput',
        JSON.stringify(metrics),
        { expirationTtl: 600 }
      );

      this.logger.info('Throughput calculated', { rps: metrics.rps });
    } catch (error) {
      this.logger.error('Failed to calculate throughput metrics', { error: String(error) });
    }
  }

  async calculateQueueMetrics(): Promise<void> {
    try {
      // Get pending event count from D1
      const result = await this.db.prepare(`
        SELECT COUNT(*) as pending_count FROM events WHERE status = 'pending'
      `).first() as any;

      const queueDepth = result?.pending_count || 0;

      // Get failed count for DLQ
      const failedResult = await this.db.prepare(`
        SELECT COUNT(*) as failed_count FROM events WHERE status = 'failed'
      `).first() as any;

      const failedCount = failedResult?.failed_count || 0;

      const metrics = {
        queue_depth: queueDepth,
        dlq_count: failedCount,
        timestamp: new Date().toISOString(),
      };

      await this.kv.put(
        'metrics:queue',
        JSON.stringify(metrics),
        { expirationTtl: 300 }
      );

      this.logger.info('Queue metrics calculated', metrics);
    } catch (error) {
      this.logger.error('Failed to calculate queue metrics', { error: String(error) });
    }
  }

  async calculateCPUMetrics(): Promise<void> {
    try {
      const result = await this.db.prepare(`
        SELECT cpu_ms FROM log_entries
        WHERE cpu_ms > 0
        ORDER BY timestamp DESC
        LIMIT 1000
      `).all();

      if (!result.results || result.results.length === 0) return;

      const cpuTimes = (result.results as any[])
        .map(r => r.cpu_ms)
        .sort((a, b) => a - b);

      const metrics = {
        p50: this.percentile(cpuTimes, 50),
        p95: this.percentile(cpuTimes, 95),
        p99: this.percentile(cpuTimes, 99),
        max: Math.max(...cpuTimes),
        avg: cpuTimes.reduce((a, b) => a + b, 0) / cpuTimes.length,
        timestamp: new Date().toISOString(),
      };

      await this.kv.put(
        'metrics:cpu',
        JSON.stringify(metrics),
        { expirationTtl: 3600 }
      );
    } catch (error) {
      this.logger.error('Failed to calculate CPU metrics', { error: String(error) });
    }
  }

  private percentile(sortedArray: number[], p: number): number {
    if (sortedArray.length === 0) return 0;
    const index = (p / 100) * (sortedArray.length - 1);
    const lower = Math.floor(index);
    const upper = Math.ceil(index);
    const weight = index - lower;

    if (lower === upper) {
      return sortedArray[lower];
    }

    return sortedArray[lower] * (1 - weight) + sortedArray[upper] * weight;
  }

  private async storeMetricHistory(
    type: string,
    endpoint: string | null,
    value: number,
    unit: string
  ): Promise<void> {
    const now = new Date().toISOString();
    const result = await this.db.prepare(`
      SELECT COUNT(*) as total FROM log_entries WHERE timestamp > ?
    `).bind(new Date(Date.now() - 60000).toISOString()).first() as any;

    const dataPoints = result?.total || 0;

    await this.db.prepare(`
      INSERT INTO metrics_history (metric_id, metric_type, endpoint, value, unit, timestamp, data_points, confidence)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    `).bind(
      crypto.randomUUID(),
      type,
      endpoint || null,
      value,
      unit,
      now,
      dataPoints,
      dataPoints > 100 ? 1.0 : dataPoints / 100
    ).run();
  }

  async runAllMetricsCalculations(): Promise<void> {
    await Promise.all([
      this.calculateLatencyPercentiles(),
      this.calculateErrorRate(),
      this.calculateThroughput(),
      this.calculateQueueMetrics(),
      this.calculateCPUMetrics(),
    ]);
  }
}
```

### Metrics Update Scheduler

```typescript
// src/lib/metrics-scheduler.ts
export class MetricsScheduler {
  constructor(
    private calculator: MetricsCalculator,
    private logger: any
  ) {}

  startScheduler(): void {
    // Run metrics calculations every 30 seconds
    setInterval(() => {
      this.calculator.runAllMetricsCalculations()
        .catch(err => this.logger.error('Metrics update failed', { error: String(err) }));
    }, 30000);

    // Run immediately on startup
    this.calculator.runAllMetricsCalculations()
      .catch(err => this.logger.error('Initial metrics update failed', { error: String(err) }));
  }
}
```

## Implementation Workflow

1. **Create D1 metrics_history table**
   - Define schema with metric_type, endpoint, value, unit
   - Add appropriate indexes

2. **Implement MetricsCalculator class**
   - Add latency percentile calculation method
   - Add error rate calculation method
   - Add throughput calculation method
   - Add queue depth method
   - Add CPU metrics method

3. **Implement Percentile Algorithm**
   - Linear interpolation percentile calculation
   - Efficient for sorted arrays

4. **Add KV Storage**
   - Store metrics in KV with TTL
   - Structure metrics by type and endpoint

5. **Implement Scheduler**
   - Run metrics calculations every 30 seconds
   - Log calculation results

6. **Test Calculations**
   - Send test requests to create logs
   - Verify metrics calculated correctly
   - Check KV contains latest metrics
   - Verify percentiles are in correct order

## Verification Checklist

- [ ] metrics_history table created with correct schema
- [ ] Latency percentiles calculated for each endpoint
- [ ] p50 < p95 < p99 always holds true
- [ ] Error rate calculation correct (e.g., 2 errors out of 100 requests = 2%)
- [ ] Queue depth matches pending events in D1
- [ ] Throughput calculated in requests/second
- [ ] Metrics stored in KV with correct TTL
- [ ] Metrics update every 30 seconds
- [ ] Percentile calculations handle edge cases (empty, single value, etc)
- [ ] CPU metrics calculated from cpu_ms field
- [ ] All metrics have timestamp
- [ ] No metrics calculations exceed 1 second

## Notes

- Percentile calculations are efficient and approximate
- KV eventually consistent, but metrics update frequently enough for practical use
- Historical metrics in D1 enable trend analysis and alerting
- Scheduler runs independently, doesn't block other operations
- Metrics calculations should be non-blocking and logged on error

## Related Stories

- **4.2:** Log Processing - provides log_entries data for metrics calculations
- **4.4:** UI Logs Display - queries metrics for dashboard display
- **4.5:** UI Metrics Enhancement - visualizes these metrics with charts
