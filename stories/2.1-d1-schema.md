---
title: "Epic 2.1 - D1 Schema: Create Events Table with Proper Indexes"
status: "Ready for Development"
epic: "Epic 2: Event Processing & Storage + Metrics Display"
priority: "P0"
acceptance_criteria:
  - "D1 database initialized with events table containing all required fields: event_id, payload, metadata, status, created_at, updated_at, retry_count"
  - "event_id field configured as TEXT PRIMARY KEY with UUID storage"
  - "payload field stored as JSON with NOT NULL constraint"
  - "metadata field stored as JSON with nullable support"
  - "status field enforces CHECK constraint restricting to pending|delivered|failed"
  - "created_at and updated_at fields store ISO-8601 timestamps as TEXT"
  - "retry_count field initialized as INTEGER DEFAULT 0"
  - "Composite index created on (status, created_at) for efficient inbox queries"
  - "Single column indexes created on status and created_at separately"
  - "Migration script executes without errors on fresh database"
  - "SELECT query returns all columns with correct data types"
  - "INSERT operation with sample event data succeeds"
  - "Verify index usage: EXPLAIN QUERY PLAN shows index usage for filtered queries"
  - "Edge case: Null metadata accepted, non-null payload rejected on INSERT"
  - "Performance baseline: Can insert 1000 events in < 100ms"
created_at: "2025-11-10"
modified_at: "2025-11-10"
story_size: "Medium"
depends_on: "Epic 1.1 - Project Setup"
---

## Summary

Create the D1 database schema for the events table with proper indexing to support efficient event storage and retrieval. This is the persistence layer foundation for Epic 2.

## Business Value

Establishes durable event storage foundation. Without this schema, events cannot be persisted, and the entire event processing pipeline fails downstream.

## Technical Requirements

### D1 Database Schema

**File Location:** `src/db/schema.sql`

**Events Table Definition:**

```sql
CREATE TABLE events (
  event_id TEXT PRIMARY KEY,
  payload JSON NOT NULL,
  metadata JSON,
  status TEXT NOT NULL CHECK(status IN ('pending', 'delivered', 'failed')),
  created_at TEXT NOT NULL,
  updated_at TEXT NOT NULL,
  retry_count INTEGER DEFAULT 0
);
```

**Index Creation:**

```sql
-- Single-column indexes for WHERE clause filtering
CREATE INDEX idx_events_status ON events(status);
CREATE INDEX idx_events_created_at ON events(created_at);

-- Composite index for inbox queries with both status and timestamp
CREATE INDEX idx_events_status_created ON events(status, created_at);
```

**Rationale (from architecture.md):**
- TEXT PRIMARY KEY for event_id (UUID stored as string)
- JSON columns for flexible payload/metadata structures
- CHECK constraint enforces status enum-like behavior without explicit ENUM type
- Indexes optimize common query patterns: filter by status, range by timestamp
- Composite index covers most inbox queries (status + time range)

### Implementation Strategy

**Step 1: Create Migration File**

Create `src/db/migrations/001-init-events-table.sql` containing the full schema above. This enables future migration management if needed.

**Step 2: Database Initialization Function**

Create `src/db/initialize.ts`:

```typescript
export async function initializeDatabase(db: D1Database): Promise<void> {
  // Execute schema.sql to create tables and indexes
  const schema = `
    CREATE TABLE IF NOT EXISTS events (
      event_id TEXT PRIMARY KEY,
      payload JSON NOT NULL,
      metadata JSON,
      status TEXT NOT NULL CHECK(status IN ('pending', 'delivered', 'failed')),
      created_at TEXT NOT NULL,
      updated_at TEXT NOT NULL,
      retry_count INTEGER DEFAULT 0
    );

    CREATE INDEX IF NOT EXISTS idx_events_status ON events(status);
    CREATE INDEX IF NOT EXISTS idx_events_created_at ON events(created_at);
    CREATE INDEX IF NOT EXISTS idx_events_status_created ON events(status, created_at);
  `;

  await db.exec(schema);
}
```

**Step 3: Query Helper Functions**

Create `src/db/queries.ts` with typed query builders:

```typescript
import { Event, CreateEventInput } from '../types/events';

export class EventQueries {
  constructor(private db: D1Database) {}

  async createEvent(input: CreateEventInput): Promise<Event> {
    const now = new Date().toISOString();
    const { event_id, payload, metadata } = input;

    const result = await this.db
      .prepare(`
        INSERT INTO events (event_id, payload, metadata, status, created_at, updated_at, retry_count)
        VALUES (?, ?, ?, ?, ?, ?, 0)
        RETURNING *
      `)
      .bind(
        event_id,
        JSON.stringify(payload),
        metadata ? JSON.stringify(metadata) : null,
        'pending',
        now,
        now
      )
      .first<Event>();

    return result!;
  }

  async getEventsByStatus(status: 'pending' | 'delivered' | 'failed'): Promise<Event[]> {
    return await this.db
      .prepare('SELECT * FROM events WHERE status = ? ORDER BY created_at DESC')
      .bind(status)
      .all<Event>();
  }

  async getEventsByStatusAndTimeRange(
    status: string,
    from: string,
    to: string,
    limit: number = 50,
    offset: number = 0
  ): Promise<Event[]> {
    return await this.db
      .prepare(`
        SELECT * FROM events
        WHERE status = ? AND created_at >= ? AND created_at <= ?
        ORDER BY created_at DESC
        LIMIT ? OFFSET ?
      `)
      .bind(status, from, to, limit, offset)
      .all<Event>();
  }

  async getTotalByStatus(status: string): Promise<number> {
    const result = await this.db
      .prepare('SELECT COUNT(*) as count FROM events WHERE status = ?')
      .bind(status)
      .first<{ count: number }>();

    return result?.count || 0;
  }

  async updateEventStatus(
    eventId: string,
    newStatus: 'pending' | 'delivered' | 'failed'
  ): Promise<void> {
    const now = new Date().toISOString();

    await this.db
      .prepare('UPDATE events SET status = ?, updated_at = ? WHERE event_id = ?')
      .bind(newStatus, now, eventId)
      .run();
  }

  async incrementRetryCount(eventId: string): Promise<void> {
    const now = new Date().toISOString();

    await this.db
      .prepare(`
        UPDATE events
        SET retry_count = retry_count + 1, updated_at = ?
        WHERE event_id = ?
      `)
      .bind(now, eventId)
      .run();
  }
}
```

### Type Definitions

Create `src/types/events.ts`:

```typescript
export interface Event {
  event_id: string;
  payload: Record<string, any>;
  metadata?: Record<string, any>;
  status: 'pending' | 'delivered' | 'failed';
  created_at: string;
  updated_at: string;
  retry_count: number;
}

export interface CreateEventInput {
  event_id: string;
  payload: Record<string, any>;
  metadata?: Record<string, any>;
}
```

### Database Binding in Worker

From wrangler.toml (already configured in Epic 1.1):

```toml
[[d1_databases]]
binding = "DB"
database_name = "triggers-api"
database_id = "unique-id-auto-generated"
```

The `env.DB` binding provides access to the D1 database instance.

### Performance Considerations

**Index Strategy:**
- `idx_events_status`: Supports quick filtering for inbox queries (e.g., "show all pending events")
- `idx_events_created_at`: Supports range queries for time-based filtering
- `idx_events_status_created`: Composite index covers typical inbox query (status + time range)

**Query Optimization:**
- Most inbox queries filter by status AND created_at range, so composite index is primary optimization
- Single-column indexes available as fallback for individual column filters
- No full-text search indexes needed (MVP scope)

### Edge Cases & Constraints

**Null Handling:**
- payload MUST be NOT NULL (every event requires data)
- metadata MAY be NULL (optional supplemental data)
- status CHECK constraint prevents invalid values at database level

**Data Type Consistency:**
- JSON fields store serialized JSON strings (D1 SQLite limitation)
- Timestamps stored as ISO-8601 strings for consistency across platforms
- event_id stored as TEXT (UUID format: "550e8400-e29b-41d4-a716-446655440000")

**Concurrency:**
- D1 SQLite is single-writer (acceptable for this scale)
- Cloudflare handles multiple readers automatically
- No row-level locking needed for MVP scope

### Testing Verification

**Manual Testing Steps:**

1. **Initialize Database:**
   ```bash
   npx wrangler dev
   # Visit http://localhost:8787/init-db (endpoint to be created in Epic 1.2)
   # Verify: Console shows "Database initialized successfully"
   ```

2. **Insert Sample Event:**
   ```sql
   INSERT INTO events (
     event_id, payload, metadata, status, created_at, updated_at, retry_count
   ) VALUES (
     'test-uuid-001',
     '{"user_id":"123","action":"login"}',
     '{"source":"auth-service"}',
     'pending',
     '2025-11-10T12:00:00Z',
     '2025-11-10T12:00:00Z',
     0
   );
   ```

3. **Query Verification:**
   ```sql
   -- Verify all columns exist
   SELECT * FROM events;

   -- Verify indexes exist
   PRAGMA index_list(events);

   -- Verify composite index is used
   EXPLAIN QUERY PLAN
   SELECT * FROM events WHERE status = 'pending' AND created_at >= '2025-11-10T00:00:00Z';
   ```

4. **Performance Test:**
   - Insert 1000 events with sequential timestamps
   - Measure insertion time: target < 100ms batch
   - Run filtered query: should return results < 50ms

5. **Constraint Validation:**
   ```sql
   -- Should fail: invalid status
   INSERT INTO events (..., status) VALUES (..., 'invalid');

   -- Should fail: missing payload
   INSERT INTO events (payload, metadata, status, created_at, updated_at)
   VALUES (NULL, '{}', 'pending', '...', '...');

   -- Should succeed: null metadata
   INSERT INTO events (event_id, payload, metadata, status, created_at, updated_at)
   VALUES ('test', '{}', NULL, 'pending', '...', '...');
   ```

---

## Implementation Notes

### What Gets Done

1. Create `src/db/schema.sql` with complete events table definition and indexes
2. Create `src/db/migrations/001-init-events-table.sql` for migration management
3. Create `src/db/initialize.ts` with `initializeDatabase()` function
4. Create `src/db/queries.ts` with `EventQueries` class containing all CRUD helpers
5. Create `src/types/events.ts` with TypeScript interfaces for Event and CreateEventInput
6. Update `src/types/env.ts` to include D1Database binding type
7. Verify wrangler.toml has correct D1 binding configuration
8. Test locally: `npx wrangler dev` and verify database initialization
9. Create test file: `test/db/queries.test.ts` with basic sanity tests

### Development Workflow

1. Use `npx wrangler d1 execute triggers-api --file=src/db/schema.sql` to apply schema
2. Access database shell: `npx wrangler d1 execute triggers-api` (local mode in wrangler dev)
3. Run sample INSERT/SELECT to verify schema
4. Commit: `git add src/db/ && git commit -m "feat: D1 schema with indexes for events table"`

### Key Architecture Decisions (from architecture.md)

**SQLite via D1:** Chosen for managed infrastructure, edge-native replication, and query flexibility

**JSON for Payloads:** Allows flexible event structures without pre-defining all fields

**Timestamp Storage:** ISO-8601 strings instead of UNIX timestamps for clarity and timezone handling

---

## Acceptance Criteria Verification Checklist

### Database Schema Verification
- [ ] `CREATE TABLE events` executes without errors
- [ ] All 7 columns created with correct data types
- [ ] PRIMARY KEY constraint on event_id verified
- [ ] CHECK constraint on status verified (only pending|delivered|failed accepted)
- [ ] NOT NULL constraint on payload verified (NULL insert rejected)
- [ ] DEFAULT value 0 on retry_count verified
- [ ] JSON columns accept valid JSON data

### Index Verification
- [ ] `idx_events_status` index created
- [ ] `idx_events_created_at` index created
- [ ] `idx_events_status_created` composite index created
- [ ] PRAGMA index_list shows all 3 indexes
- [ ] EXPLAIN QUERY PLAN shows indexes used in filtered queries

### Query Helper Verification
- [ ] EventQueries class exports all CRUD methods
- [ ] createEvent() returns Event with all fields
- [ ] getEventsByStatus() returns array of events
- [ ] getEventsByStatusAndTimeRange() respects limit/offset
- [ ] updateEventStatus() modifies status correctly
- [ ] incrementRetryCount() increases counter
- [ ] Type definitions match database schema

### Performance Verification
- [ ] Insert 1000 events completes in < 100ms
- [ ] Query filtered by status completes in < 50ms
- [ ] Query range by created_at completes in < 50ms
- [ ] Composite index query completes in < 50ms
- [ ] No N+1 query patterns in helper functions

### TypeScript Verification
- [ ] Event interface matches database schema
- [ ] CreateEventInput has required fields
- [ ] All database method signatures properly typed
- [ ] No `any` types (use explicit interfaces)
- [ ] TypeScript strict mode passes

---

## Dependencies & Context

**From:** docs/PRD.md (Epic 2 section - Event Processing & Storage)
**Architecture:** docs/architecture.md (Data Architecture - D1 Schema section)
**Enables:** Epic 2.2 (Queue Consumer), Epic 2.3 (Workflow), Epic 2.4 (Event Storage)

**Database Bindings:** Already configured in Epic 1.1 (wrangler.toml)
**Types:** Referenced by all future event processing stories

---

## Dev Notes

- D1 is managed SQLite on Cloudflare edge - no external database needed
- JSON columns store serialized strings, parse/stringify in application code
- Indexes are critical for performance as event table grows
- Use typed queries (TypeScript interfaces) for type safety and consistency
- Test INSERT/UPDATE/SELECT locally before pushing to remote D1
- Keep migration files for audit trail (even if not used by tooling)

---

## Testing Considerations

### Local Development Testing

```bash
# Start local Wrangler environment with D1 support
npx wrangler dev

# In another terminal, test database:
npx wrangler d1 execute triggers-api --local

# Or via API endpoint (once Event Ingestion created):
curl -X POST http://localhost:8787/events \
  -H "Authorization: Bearer test-token" \
  -H "Content-Type: application/json" \
  -d '{"payload":{"test":"data"}}'
```

### Database Shell Commands

```sql
-- Create schema
.read src/db/schema.sql

-- Verify tables
.tables

-- Check indexes
PRAGMA index_list(events);

-- Test insert
INSERT INTO events (event_id, payload, metadata, status, created_at, updated_at, retry_count)
VALUES ('test-1', '{"data":"test"}', NULL, 'pending', datetime('now'), datetime('now'), 0);

-- Test query with index
EXPLAIN QUERY PLAN
SELECT * FROM events WHERE status = 'pending' ORDER BY created_at DESC LIMIT 50;

-- Verify data
SELECT * FROM events;
```

---
